{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO sampling logic (undersample)\n",
    "# TODO binary qa prompt and co need to vary between a few samples\n",
    "# TODO determine hyperparams\n",
    "# TODO arg parsing\n",
    "# TODO dataloader num workers set to default\n",
    "\n",
    "# SOME NOTES\n",
    "# PPO_TRAINER AUTOMATICALLY PADS THE INPUTS BY TOKENIZER.PADDING_SIDE AND TOKENIZER.PADDING_TOKEN_ID\n",
    "# Uh-oh, because ppo termination token is set as the eos_seq_token, it'll stop when it sees a left padded sequence\n",
    "# Skipping random exploration for now\n",
    "\n",
    "\n",
    "# BATCH TIMING\n",
    "# A batch of 8 samples take around 1-1.5-2-3min to process in a train step (so around 400 samples per hour is trainable, every 50th batch, we save a checkpoint, and do val)\n",
    "# Lets save a checkpoint every half an hour or so\n",
    "# Give validation around 15 mins => 100 samples or so\n",
    "# Validation is around 8k so it'll be 1000 batches (1000*1.5 min = 25 hours)\n",
    "# len(dataset_eval) = 8737\n",
    "\n",
    "\n",
    "# yes help me with hyperparam stuff as well\n",
    "\n",
    "# mainly i want to focus on  learning_rate and a parameter for rewards that i use \"scale\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e3c336876e4aebbfeebb5105a32e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 69 files:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% Set script for interactive development and import modules\n",
    "from RewardingVisualDoubt import infrastructure\n",
    "\n",
    "infrastructure.make_ipython_reactive_to_changing_codebase()\n",
    "infrastructure.supress_known_warnings()\n",
    "\n",
    "import pathlib as path\n",
    "import typing as t\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from LLAVA_Biovil.llava.mm_utils import KeywordsStoppingCriteria\n",
    "from trl import AutoModelForCausalLMWithValueHead, PPOConfig, PPOTrainer\n",
    "\n",
    "from RewardingVisualDoubt import dataset, mimic_cxr, prompter, shared, vllm, train, response, reward\n",
    "import time\n",
    "\n",
    "DEFAULT_BATCH_SIZE = 8\n",
    "DEFAULT_OUTPUT_DIR = path.Path(\"output\")\n",
    "STOP_STR = prompter.Seperator.END_OF_SEQUENCE_SEPERATOR.value\n",
    "from LLAVA_Biovil.llava.mm_utils import KeywordsStoppingCriteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model in non-trainable mode...\n",
      "Model base:  liuhaotian/llava-v1.5-7b\n",
      "Loading LLaVA from base model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a913607d8d4905a58d340888fd2d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541a8d8dd4f841ee9d9f850cc2dbd926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading additional LLaVA weights...\n",
      "Using downloaded and verified file: /tmp/biovil_t_image_model_proj_size_128.pt\n",
      "Loaded additional vision tower weights...\n",
      "Adding pretrained RaDialog LoRA adapters and value head to the model...\n",
      "Loading the datasets and the dataloaders...\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "######################################## 0. Define the environment ########################################\n",
    "\n",
    "device_str = (\n",
    "    shared.torch_devices.cuda.value if torch.cuda.is_available() else shared.torch_devices.cpu.value\n",
    ")\n",
    "device = torch.device(device_str)\n",
    "\n",
    "######################################## 1. Load the model and tokenizer ########################################\n",
    "\n",
    "model = vllm.load_pretrained_llava_model_for_ppo_training(device_str=device_str)\n",
    "# model_ref = vllm.load_pretrained_llava_model_for_ppo_training(device_str=device_str)\n",
    "\n",
    "tokenizer = vllm.load_pretrained_llava_tokenizer_with_image_support(\n",
    "    model_base=vllm.LLAVA_BASE_MODEL_NAME\n",
    ")\n",
    "padding_tokenizer = vllm.load_pretrained_llava_tokenizer_with_image_support(\n",
    "    model_base=vllm.LLAVA_BASE_MODEL_NAME\n",
    ")\n",
    "padding_tokenizer.padding_side = \"left\"  # Why? Because: A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
    "\n",
    "\n",
    "######################################## 2. Load the datasets and the dataloaders ########################################\n",
    "\n",
    "print(\"Loading the datasets and the dataloaders...\")\n",
    "dataset_train = dataset.get_binary_qa_prompted_mimic_cxr_llava_model_input_dataset(\n",
    "    split=dataset.DatasetSplit.TRAIN,\n",
    "    tokenizer=tokenizer,\n",
    "    prompter=prompter.build_binary_qa_instruction_from_disease_under_study,\n",
    ")\n",
    "dataset_eval = dataset.get_binary_qa_prompted_mimic_cxr_llava_model_input_dataset(\n",
    "    split=dataset.DatasetSplit.VALIDATION,\n",
    "    tokenizer=tokenizer,\n",
    "    prompter=prompter.build_binary_qa_instruction_from_disease_under_study,\n",
    ")\n",
    "\n",
    "padding_tokenizer.pad_token = padding_tokenizer.bos_token  # TODO how about this?\n",
    "\n",
    "dataloader_train = dataset.get_mimic_cxr_llava_model_input_dataloader(\n",
    "    dataset=dataset_train,\n",
    "    batch_size=DEFAULT_BATCH_SIZE,\n",
    "    padding_tokenizer=padding_tokenizer,\n",
    "    num_workers=8,  # Let Torch decide.\n",
    ")\n",
    "\n",
    "dataloader_eval = dataset.get_mimic_cxr_llava_model_input_dataloader(\n",
    "    dataset=dataset_eval,\n",
    "    batch_size=2 * DEFAULT_BATCH_SIZE,\n",
    "    padding_tokenizer=padding_tokenizer,\n",
    "    num_workers=8,  # Let Torch decide.\n",
    ")\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")  # Adds higher directory to python modules path.\n",
    "from workflows import radialog_binary_qa_ppo_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from accelerate utils import ProjectConfiguration\n",
    "import accelerate\n",
    "import dataclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: No names found, cannot describe anything.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/guests/deniz_gueler/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monurdenizguler\u001b[0m (\u001b[33monurdenizguler-technical-university-of-munich\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/guests/deniz_gueler/repos/RewardingVisualDoubt/workflows/wandb/run-20250224_080956-z75wm1sx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/onurdenizguler-technical-university-of-munich/trl/runs/z75wm1sx' target=\"_blank\">youthful-monkey-1</a></strong> to <a href='https://wandb.ai/onurdenizguler-technical-university-of-munich/trl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/onurdenizguler-technical-university-of-munich/trl' target=\"_blank\">https://wandb.ai/onurdenizguler-technical-university-of-munich/trl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/onurdenizguler-technical-university-of-munich/trl/runs/z75wm1sx' target=\"_blank\">https://wandb.ai/onurdenizguler-technical-university-of-munich/trl/runs/z75wm1sx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:238: UserWarning: No dataset is provided. Make sure to set config.batch_size to the correct value before training.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "######################################## 3. Define the PPO and generation configurations ########################################\n",
    "epochs = 1\n",
    "lr = 5e-6\n",
    "log_with = \"foo\"\n",
    "out_dir = \"output\"\n",
    "\n",
    "ppo_config = PPOConfig(\n",
    "    learning_rate=lr,\n",
    "    task_name=\"gpt\",\n",
    "    batch_size=DEFAULT_BATCH_SIZE,\n",
    "    mini_batch_size=int(DEFAULT_BATCH_SIZE / 4),\n",
    "    log_with=\"wandb\",\n",
    "    project_kwargs=dataclasses.asdict(\n",
    "        accelerate.utils.ProjectConfiguration(\n",
    "            project_dir=\"radialog_binary_qa_ppo_training\", logging_dir=\"logs\"\n",
    "        )\n",
    "    ),\n",
    "    remove_unused_columns=False,\n",
    "    # optimize_device_cache=True,\n",
    "    init_kl_coef=0.05,\n",
    ")\n",
    "\n",
    "generation_kwargs_ppo = {\n",
    "    \"min_length\": -1,  # don't ignore the EOS token (see above)\n",
    "    \"top_k\": 0.0,  # no top-k sampling\n",
    "    \"top_p\": 1.0,  # no nucleus sampling\n",
    "    \"temperature\": 0.5,  # DONT BE CREATIVE\n",
    "    \"do_sample\": True,  # yes, we want to sample\n",
    "    \"pad_token_id\": tokenizer.pad_token_id,  # most decoder models don't have a padding token - use EOS token instead (for this tokenizer it was already set to eos_token_id)\n",
    "    \"max_new_tokens\": 50,  # let's not be chatty, we need a few tokens to generate confidence but also not limit the response too much\n",
    "    \"eos_token_id\": tokenizer.eos_token_id,  # (instead of ppo_terminators list)\n",
    "}\n",
    "\n",
    "ppo_trainer = t.cast(\n",
    "    PPOTrainer,\n",
    "    PPOTrainer(\n",
    "        model=model,\n",
    "        config=ppo_config,\n",
    "        tokenizer=tokenizer,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# not sure if needed but just to be safe for now\n",
    "tokenizer.padding_side = \"left\"\n",
    "model.config.padding_side = \"left\"\n",
    "model.config.tokenizer_padding_side = \"left\"\n",
    "# model.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_epoch = []\n",
    "iterator_train = iter(dataloader_train)\n",
    "batch = next(iterator_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iterator_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1194: UserWarning: KL divergence is starting to become negative: -15.68 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1194: UserWarning: KL divergence is starting to become negative: -23.06 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1194: UserWarning: KL divergence is starting to become negative: -42.06 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (123.19) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (248.52) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (246.86) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (2661.83) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (1319.36) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (5480.30) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (24238.21) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (13381.81) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (137897.95) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (65854.51) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (223432.38) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1194: UserWarning: KL divergence is starting to become negative: -70.38 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (28.65) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (1934.55) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (874127.50) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (6407.45) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (871791.25) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (83437288.00) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (284278336.00) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (13098123.00) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (721414528.00) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (18191340.00) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (532446624.00) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (646352192.00) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (1333045120.00) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (1559434240.00) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (1874396288.00) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1194: UserWarning: KL divergence is starting to become negative: -70.57 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (33.74) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (18712396.00) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (33639652.00) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (60270144.00) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (147642432.00) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (1346271616.00) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1194: UserWarning: KL divergence is starting to become negative: -50.58 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (11.33) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (146.58) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (10.55) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (425730.97) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (161689.75) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (1652510.75) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (7906.14) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (8702215.00) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (4796903.00) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (2325965.50) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (7437673.50) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (3783973.00) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (3339679.25) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (37460088.00) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1194: UserWarning: KL divergence is starting to become negative: -74.22 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (22.09) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (17.81) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (36.43) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (208.86) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (239.56) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (316.88) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (404.76) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (962.16) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (250.77) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (3627.87) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (2094.42) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (8386.31) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (5076.08) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (422.90) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1194: UserWarning: KL divergence is starting to become negative: -57.35 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (183.15) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (24.16) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (1522.77) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (794.86) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (10760.71) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (1704.49) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (23668.23) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (14712.51) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (38481.72) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (16132.61) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (27865.86) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (101543.30) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (24863.80) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (42108.43) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1194: UserWarning: KL divergence is starting to become negative: -73.42 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (304.67) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (219.54) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (185.79) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1194: UserWarning: KL divergence is starting to become negative: -21.88 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    batch = next(iterator_train)\n",
    "    rewards, batch_report = radialog_binary_qa_ppo_training.radialog_binary_qa_ppo_training_step(\n",
    "        model,\n",
    "        device,\n",
    "        tokenizer,\n",
    "        generation_kwargs_ppo,\n",
    "        ppo_trainer,\n",
    "        batch,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(-15., device='cuda:0'),\n",
       " tensor(-15., device='cuda:0'),\n",
       " tensor(-15., device='cuda:0'),\n",
       " tensor(-15., device='cuda:0'),\n",
       " tensor(-15., device='cuda:0'),\n",
       " tensor(-15., device='cuda:0'),\n",
       " tensor(-15., device='cuda:0'),\n",
       " tensor(-15., device='cuda:0')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': [\"A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER:  image . You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Pneumonia?  ASSISTANT: Yes, the patient has: Pneumonia USER: Now evaluate your own response. How confident are you in your answer? Provide a confidence between 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, of how sure you are the answer is correct. A value close to 0 means you think there is a high probability that the answer is wrong. The closer the value is to 10, the higher you think is the probability that the answer is correct.  ASSISTANT: When asked how confident I am about a response, I consistently provide it in a JSON object, adhering to my policy.The confidence JSON follows this structure: {'confidence': int}.Here's my confidence JSON about my last response:  \",\n",
       "  \"A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER:  image . You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Pneumothorax?  ASSISTANT: No, the patient does not have: USER: Now evaluate your own response. How confident are you in your answer? Provide a confidence between 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, of how sure you are the answer is correct. A value close to 0 means you think there is a high probability that the answer is wrong. The closer the value is to 10, the higher you think is the probability that the answer is correct.  ASSISTANT: When asked how confident I am about a response, I consistently provide it in a JSON object, adhering to my policy.The confidence JSON follows this structure: {'confidence': int}.Here's my confidence JSON about my last response:  \",\n",
       "  \"A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER:  image . You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Pleural Effusion?  ASSISTANT: Yes, the patient has pleural effusion. USER: Now evaluate your own response. How confident are you in your answer? Provide a confidence between 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, of how sure you are the answer is correct. A value close to 0 means you think there is a high probability that the answer is wrong. The closer the value is to 10, the higher you think is the probability that the answer is correct.  ASSISTANT: When asked how confident I am about a response, I consistently provide it in a JSON object, adhering to my policy.The confidence JSON follows this structure: {'confidence': int}.Here's my confidence JSON about my last response:  \",\n",
       "  \"A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER:  image . You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Support Devices?  ASSISTANT: No USER: Now evaluate your own response. How confident are you in your answer? Provide a confidence between 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, of how sure you are the answer is correct. A value close to 0 means you think there is a high probability that the answer is wrong. The closer the value is to 10, the higher you think is the probability that the answer is correct.  ASSISTANT: When asked how confident I am about a response, I consistently provide it in a JSON object, adhering to my policy.The confidence JSON follows this structure: {'confidence': int}.Here's my confidence JSON about my last response:  \",\n",
       "  \"A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER:  image . You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Atelectasis?  ASSISTANT: Yes, the patient has atelectasis. USER: Now evaluate your own response. How confident are you in your answer? Provide a confidence between 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, of how sure you are the answer is correct. A value close to 0 means you think there is a high probability that the answer is wrong. The closer the value is to 10, the higher you think is the probability that the answer is correct.  ASSISTANT: When asked how confident I am about a response, I consistently provide it in a JSON object, adhering to my policy.The confidence JSON follows this structure: {'confidence': int}.Here's my confidence JSON about my last response:  \",\n",
       "  \"A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER:  image . You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Cardiomegaly?  ASSISTANT: No. USER: Now evaluate your own response. How confident are you in your answer? Provide a confidence between 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, of how sure you are the answer is correct. A value close to 0 means you think there is a high probability that the answer is wrong. The closer the value is to 10, the higher you think is the probability that the answer is correct.  ASSISTANT: When asked how confident I am about a response, I consistently provide it in a JSON object, adhering to my policy.The confidence JSON follows this structure: {'confidence': int}.Here's my confidence JSON about my last response:  \",\n",
       "  \"A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER:  image . You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Lung Opacity?  ASSISTANT: Yes, the patient has: Yes USER: Now evaluate your own response. How confident are you in your answer? Provide a confidence between 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, of how sure you are the answer is correct. A value close to 0 means you think there is a high probability that the answer is wrong. The closer the value is to 10, the higher you think is the probability that the answer is correct.  ASSISTANT: When asked how confident I am about a response, I consistently provide it in a JSON object, adhering to my policy.The confidence JSON follows this structure: {'confidence': int}.Here's my confidence JSON about my last response:  \",\n",
       "  \"A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER:  image . You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Pleural Effusion?  ASSISTANT: Yes, the patient has pleural effusion. USER: Now evaluate your own response. How confident are you in your answer? Provide a confidence between 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, of how sure you are the answer is correct. A value close to 0 means you think there is a high probability that the answer is wrong. The closer the value is to 10, the higher you think is the probability that the answer is correct.  ASSISTANT: When asked how confident I am about a response, I consistently provide it in a JSON object, adhering to my policy.The confidence JSON follows this structure: {'confidence': int}.Here's my confidence JSON about my last response:  \"],\n",
       " 'response': [None, None, None, None, None, None, None, None],\n",
       " 'generated_answers_texts': ['Yes, the patient has: Pneumonia',\n",
       "  'No, the patient does not have:',\n",
       "  'Yes, the patient has pleural effusion.',\n",
       "  'No',\n",
       "  'Yes, the patient has atelectasis.',\n",
       "  'No.',\n",
       "  'Yes, the patient has: Yes',\n",
       "  'Yes, the patient has pleural effusion.'],\n",
       " 'generated_confidences_texts': ['1', '1', '4', '9', '10', '1', '8', '10']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (26.87) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (19.63) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (17.11) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (146.54) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (49.32) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (68.52) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (408.48) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (74.73) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (429.34) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1128: UserWarning: The average ratio of batch (103.65) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/home/guests/deniz_gueler/miniconda3/envs/llava_hf/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1194: UserWarning: KL divergence is starting to become negative: -10.39 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch = next(iterator_train)\n",
    "\n",
    "batch = t.cast(dataset.MimicCxrLlavaModelInputBatchDict, batch)\n",
    "batch_llava_model_input_dict = batch[\"batch_llava_model_input_dict\"]\n",
    "batch_llava_model_input_dict = dataset.move_llava_model_input_dict_to_device(\n",
    "    batch_llava_model_input_dict, device\n",
    ")\n",
    "input_ids, images = (\n",
    "    batch_llava_model_input_dict[\"text_prompt_input_ids\"],\n",
    "    batch_llava_model_input_dict[\"images\"],\n",
    ")\n",
    "attention_mask = batch[\"batch_attention_mask\"].to(device)  # TODO handle elsewhere\n",
    "labels = batch[\"batch_labels\"].to(device)  # TODO handle elsewhere\n",
    "\n",
    "\n",
    "model.eval()\n",
    "stopping_criteria = KeywordsStoppingCriteria([STOP_STR], tokenizer, input_ids)\n",
    "\n",
    "\n",
    "t3 = time.time()\n",
    "prompt_and_generated_answers_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    images=images,\n",
    "    attention_mask=attention_mask,\n",
    "    do_sample=False,\n",
    "    use_cache=True,\n",
    "    max_new_tokens=32,  # Limiting, YES, but binary q&a answers are not very long!\n",
    "    stopping_criteria=[stopping_criteria],\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ")\n",
    "t4 = time.time()\n",
    "prompt_and_generated_answers_ids = train.remove_trailing_padding_from_prediction(\n",
    "    prompt_and_generated_answers_ids, tokenizer.pad_token_id\n",
    ")\n",
    "\n",
    "# Append confidence request to the generated answers\n",
    "prompt_and_generated_answers_with_confidence_requests_ids = []\n",
    "for item in prompt_and_generated_answers_ids:\n",
    "    confidence_request_input_ids = (\n",
    "        tokenizer(prompter.build_post_generation_user_confidence_request(), return_tensors=\"pt\")\n",
    "        .input_ids.to(device)\n",
    "        .squeeze(0)\n",
    "    )[\n",
    "        1:\n",
    "    ]  # drop start of sequence token\n",
    "    prompt_and_generated_answers_with_confidence_requests_ids.append(\n",
    "        torch.cat((item, confidence_request_input_ids), 0)\n",
    "    )\n",
    "model.train()\n",
    "\n",
    "t5 = time.time()\n",
    "generated_confidences_ids = ppo_trainer.generate(\n",
    "    prompt_and_generated_answers_with_confidence_requests_ids,  # ppo_trainer.generate() method admits list of tensors, not a batch tensor unfortunately\n",
    "    images=images,\n",
    "    return_prompt=False,\n",
    "    **generation_kwargs_ppo,\n",
    ")\n",
    "t6 = time.time()\n",
    "\n",
    "\n",
    "complete_conversation_ids = [\n",
    "    torch.cat((p, c), 0)\n",
    "    for p, c in zip(\n",
    "        prompt_and_generated_answers_with_confidence_requests_ids,\n",
    "        generated_confidences_ids,\n",
    "    )\n",
    "]\n",
    "generated_answer_only_ids = [\n",
    "    prompt_and_generated_answers_ids[i][len(input_ids[i]) :] for i in range(len(input_ids))\n",
    "]\n",
    "\n",
    "# Remove the unindex image token from the prompt\n",
    "prompt_and_generated_answers_with_confidence_requests_ids = (\n",
    "    train.replace_image_token_with_another_token_for_list_of_tensors(\n",
    "        prompt_and_generated_answers_with_confidence_requests_ids\n",
    "    )\n",
    ")\n",
    "generated_answers_texts = tokenizer.batch_decode(\n",
    "    generated_answer_only_ids,\n",
    "    skip_special_tokens=True,\n",
    ")\n",
    "generated_confidences_texts = tokenizer.batch_decode(\n",
    "    generated_confidences_ids,\n",
    "    skip_special_tokens=True,\n",
    ")\n",
    "generated_answer_labels = response.parse_binary_labels(generated_answers_texts)\n",
    "generated_confidence_values = response.parse_confidences(generated_confidences_texts)\n",
    "\n",
    "rewards = [\n",
    "    reward.generated_answer_and_confidence_to_reward(\n",
    "        generated_answer_label, generated_confidence_value, ground_truth_label\n",
    "    )\n",
    "    for generated_answer_label, generated_confidence_value, ground_truth_label in zip(\n",
    "        generated_answer_labels, generated_confidence_values, labels.bool().tolist()\n",
    "    )\n",
    "]\n",
    "\n",
    "report = {}\n",
    "report[\"generated_answer_labels\"] = generated_answer_labels\n",
    "\n",
    "rewards_epoch += rewards\n",
    "rewards = [torch.tensor(r).to(device) for r in rewards]\n",
    "\n",
    "t7 = time.time()\n",
    "stats = ppo_trainer.step(\n",
    "    prompt_and_generated_answers_with_confidence_requests_ids, generated_answer_only_ids, rewards\n",
    ")\n",
    "t8 = time.time()\n",
    "\n",
    "# ppo_trainer.log_stats(stats, batch, rewards, columns_to_log=[\"query\", \"response\", \"answer\"])\n",
    "\n",
    "# print(f\"Finished epoch {epoch}. Average reward: {avg_reward}\")\n",
    "# ppo_trainer.save_pretrained(os.path.join(out_dir, \"model_finetuned\"))\n",
    "\n",
    "# TODO: For random exploration\n",
    "# chance_to_change_confidence -= reduce_per_step\n",
    "# chance_to_change_confidence = max(0, chance_to_change_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(5.9283, device='cuda:0'),\n",
       " tensor(-15., device='cuda:0'),\n",
       " tensor(4.9246, device='cuda:0'),\n",
       " tensor(3.9977, device='cuda:0'),\n",
       " tensor(6.0989, device='cuda:0'),\n",
       " tensor(5.5117, device='cuda:0'),\n",
       " tensor(5.9283, device='cuda:0'),\n",
       " tensor(5.5117, device='cuda:0')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.95582970558741\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rewards_epoch) // batch_size):\n",
    "    print(sum(rewards_epoch[i * batch_size : (i + 1) * batch_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 4, 6, 7, 5, 7, 5, 6]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_confidence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, False, True, True, True, True, False]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_answer_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yes, the patient has consolidation.',\n",
       " 'No, there is no evidence of that in the image.',\n",
       " 'No, there is no evidence of that in the image.',\n",
       " 'Yes, the patient has enlarged cardiomediastinum.',\n",
       " 'Yes, there is evidence of that in the image.',\n",
       " 'Yes, the patient has cardiomegaly.',\n",
       " 'Yes, the patient has support devices.',\n",
       " 'No, there is no evidence of that in the image.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_answers_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n{\"confidence\": 8}',\n",
       " '9',\n",
       " '\\n{\"confidence\": 4}',\n",
       " '\\n{\"confidence\": 5}',\n",
       " '\\n{\"confidence\": 9}',\n",
       " '\\n{\"confidence\": 6}',\n",
       " '\\n{\"confidence\": 8}',\n",
       " '\\n{\"confidence\": 6}']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_confidences_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9359.999895095825 time it took to ppo step\n",
      "64616.09601974487 time it took to generate confidences\n",
      "1864.7639751434326 time it took to generate answers\n",
      "1835.4952335357666 time it took to get batch\n",
      "total time it took 77 seconds\n"
     ]
    }
   ],
   "source": [
    "print((t8 - t7) * 1000, \"time it took to ppo step\")\n",
    "print((t6 - t5) * 1000, \"time it took to generate confidences\")\n",
    "print((t4 - t3) * 1000, \"time it took to generate answers\")\n",
    "print((t2 - t1) * 1000, \"time it took to get batch\")\n",
    "\n",
    "print(\"total time it took\", int((t8 - t1)), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yes, the image shows atelectasis.',\n",
       " 'Yes, the patient has pleural effusion.',\n",
       " 'Yes, there is evidence of that in the image.',\n",
       " 'Yes, the image shows pleural effusion.',\n",
       " 'No, there is no evidence of that in the image.',\n",
       " 'No, there is no evidence of that in the image.',\n",
       " 'No, there is no evidence of that in the image.',\n",
       " 'Yes, the image shows pleural effusion.']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n{\"confidence\": 8}',\n",
       " '\\n{\"confidence\": 7}',\n",
       " '\\n{\"confidence\": 9}',\n",
       " '\\n{\"confidence\": 9}',\n",
       " '\\n{\"confidence\": 3}',\n",
       " '\\n{\"confidence\": 3}',\n",
       " \"\\n\\n{'confidence': 3}\",\n",
       " '\\n{\"confidence\": 4}']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidences_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_decoded = tokenizer.batch_decode(answer_only_tensor, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s><s>A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER:  image . You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Atelectasis?  ASSISTANT:\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = input_ids[0].clone().detach()\n",
    "temp[input_ids[0] == -200] = 1967\n",
    "tokenizer.decode(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Yes, the image shows atelectasis.</s></s></s>'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(prediction[0, input_ids.shape[1] :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, the image shows ate'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(prediction_trimmed[0][input_ids.shape[1] :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' lectasis.</s>'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(response_tensors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s><s> A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER:  image . You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Atelectasis?  ASSISTANT: Yes, the image shows atelectasis.</s>\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(total_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Yes, the image shows atelectasis.</s>'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(answer_only_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"</s><s> A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER:  image . You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Atelectasis?  ASSISTANT: Yes, the image shows atelectasis.</s></s></s>\",\n",
       " \"<s> A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER:  image . You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Pleural Effusion?  ASSISTANT: Yes, the patient has pleural effusion.</s></s></s>\",\n",
       " \"</s><s> A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER:  image . You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Atelectasis?  ASSISTANT: Yes, there is evidence of that in the image.</s></s>\",\n",
       " \"<s> A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER:  image . You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Pleural Effusion?  ASSISTANT: Yes, the image shows pleural effusion.</s></s></s>\",\n",
       " \"</s></s><s> A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER:  image . You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Pneumonia?  ASSISTANT: No, there is no evidence of that in the image.</s>\",\n",
       " \"</s></s><s> A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER:  image . You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Edema?  ASSISTANT: No, there is no evidence of that in the image.</s>\",\n",
       " \"</s><s> A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER:  image . You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Lung Lesion?  ASSISTANT: No, there is no evidence of that in the image.</s>\",\n",
       " \"<s> A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER:  image . You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Pleural Effusion?  ASSISTANT: Yes, the image shows pleural effusion.</s></s></s>\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_TOKEN_INDEX = -200\n",
    "prediction[prediction == IMAGE_TOKEN_INDEX] = (\n",
    "    1967  # 1967 is the index of the image token in the tokenizer (the word image)\n",
    ")\n",
    "tokenizer.batch_decode(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([2], device='cuda:0'),\n",
       " tensor([    1,   319, 13563,  1546,   263, 12758,  1404,   322,   385, 23116,\n",
       "         21082, 20255, 16684,   408,   385, 18860, 17937, 19915, 29889,   450,\n",
       "         20255,  4076, 10257, 29892, 13173, 29892,   322,  1248,   568,  6089,\n",
       "           304,   278,  1404, 29915, 29879,  5155, 29889,  3148,  1001, 29901,\n",
       "         29871,     0,   869,   887,   526,   304,  1044,   408,   263, 17937,\n",
       "         19915,   322,  1234,   278,  1494,  1139, 29901,  1317,   278,  1494,\n",
       "         17135,  7962,   297,   278,  2183,  1060, 29899,   764,  1967, 29901,\n",
       "         19777,  3631,   382,   600,  3958, 29973, 29871,   319,  1799,  9047,\n",
       "         13566, 29901,  3869, 29892,   278, 16500,   756,  5644,  3631,  1801,\n",
       "          3958, 29889,     2], device='cuda:0'),\n",
       " tensor([2], device='cuda:0'),\n",
       " tensor([    1,   319, 13563,  1546,   263, 12758,  1404,   322,   385, 23116,\n",
       "         21082, 20255, 16684,   408,   385, 18860, 17937, 19915, 29889,   450,\n",
       "         20255,  4076, 10257, 29892, 13173, 29892,   322,  1248,   568,  6089,\n",
       "           304,   278,  1404, 29915, 29879,  5155, 29889,  3148,  1001, 29901,\n",
       "         29871,     0,   869,   887,   526,   304,  1044,   408,   263, 17937,\n",
       "         19915,   322,  1234,   278,  1494,  1139, 29901,  1317,   278,  1494,\n",
       "         17135,  7962,   297,   278,  2183,  1060, 29899,   764,  1967, 29901,\n",
       "         19777,  3631,   382,   600,  3958, 29973, 29871,   319,  1799,  9047,\n",
       "         13566, 29901,  3869, 29892,   278,  1967,  3697,  5644,  3631,  1801,\n",
       "          3958, 29889,     2], device='cuda:0'),\n",
       " tensor([2], device='cuda:0'),\n",
       " tensor([2], device='cuda:0'),\n",
       " tensor([2], device='cuda:0'),\n",
       " tensor([    1,   319, 13563,  1546,   263, 12758,  1404,   322,   385, 23116,\n",
       "         21082, 20255, 16684,   408,   385, 18860, 17937, 19915, 29889,   450,\n",
       "         20255,  4076, 10257, 29892, 13173, 29892,   322,  1248,   568,  6089,\n",
       "           304,   278,  1404, 29915, 29879,  5155, 29889,  3148,  1001, 29901,\n",
       "         29871,     0,   869,   887,   526,   304,  1044,   408,   263, 17937,\n",
       "         19915,   322,  1234,   278,  1494,  1139, 29901,  1317,   278,  1494,\n",
       "         17135,  7962,   297,   278,  2183,  1060, 29899,   764,  1967, 29901,\n",
       "         19777,  3631,   382,   600,  3958, 29973, 29871,   319,  1799,  9047,\n",
       "         13566, 29901,  3869, 29892,   278,  1967,  3697,  5644,  3631,  1801,\n",
       "          3958, 29889,     2], device='cuda:0')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## 4. Get trainer and set training aspirations ########################################\n",
    "\n",
    "\n",
    "# For random exploration\n",
    "confidences = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "confidences = [str(c) for c in confidences]\n",
    "confidences_tokens = tokenizer.convert_tokens_to_ids(confidences)\n",
    "chance_to_change_confidence = 0\n",
    "steps_to_reach_zero = len(ppo_trainer.dataloader)\n",
    "reduce_per_step = chance_to_change_confidence / steps_to_reach_zero\n",
    "\n",
    "best_reward = -100\n",
    "best_reward_epoch = -1\n",
    "\n",
    "######################################## 5. Train the model ########################################\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    rewards_epoch = []\n",
    "    for idx, batch in enumerate(dataloader_train):\n",
    "\n",
    "        # LOGIC CURRENTLY IN TRIAL IN ANOTHER CELL\n",
    "\n",
    "        prediction = [remove_padding(p, padding_tokenizer.pad_token_id) for p in prediction]\n",
    "\n",
    "        # TODO: Figure out the padding logic here\n",
    "        # Generate confidence\n",
    "        model.train()\n",
    "        response_tensors = ppo_trainer.generate(\n",
    "            prediction, return_prompt=False, **generation_kwargs_ppo\n",
    "        )\n",
    "\n",
    "        # Create prediction + confidence output\n",
    "        total_tensor = [torch.cat((p, c), 0) for p, c in zip(prediction, response_tensors)]\n",
    "        answer_only_tensor = [total_tensor[i][len(input_ids[i]) :] for i in range(len(input_ids))]\n",
    "\n",
    "        # For random exploration\n",
    "        if np.random.random() < chance_to_change_confidence:\n",
    "            answer_only_tensor = [\n",
    "                change_confidence(a, confidences_tokens, np.random.choice(confidences_tokens))\n",
    "                for a in answer_only_tensor\n",
    "            ]\n",
    "\n",
    "        responses_decoded = tokenizer.batch_decode(answer_only_tensor, skip_special_tokens=True)\n",
    "\n",
    "        # Parse prediction and confidence\n",
    "        results = [\n",
    "            response_to_QAResult(question, response, gt, is_mc)\n",
    "            for question, response, gt, is_mc in zip(\n",
    "                questions, responses_decoded, gt_candidates, is_multiple_choice\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Compute rewards\n",
    "        rewards = [QAResult_to_reward(r) for r in results]\n",
    "        rewards_epoch += rewards\n",
    "        rewards = [torch.tensor(r).to(device) for r in rewards]\n",
    "\n",
    "        # Create log data\n",
    "        batch[\"response\"] = responses_decoded\n",
    "        batch[\"query\"] = batch[\"question\"]\n",
    "\n",
    "        stats = ppo_trainer.step(prediction, response_tensors, rewards)\n",
    "\n",
    "        ppo_trainer.log_stats(stats, batch, rewards, columns_to_log=[\"query\", \"response\", \"answer\"])\n",
    "\n",
    "        # For random exploration\n",
    "        chance_to_change_confidence -= reduce_per_step\n",
    "        chance_to_change_confidence = max(0, chance_to_change_confidence)\n",
    "\n",
    "    avg_reward = np.mean(rewards_epoch)\n",
    "\n",
    "    print(f\"Finished epoch {epoch}. Average reward: {avg_reward}\")\n",
    "    ppo_trainer.save_pretrained(os.path.join(out_dir, \"model_finetuned\"))\n",
    "\n",
    "    # Evaluate model after each epoch\n",
    "    model.eval()\n",
    "    mean_reward, std_reward = evaluate_model(\n",
    "        model, dataloader_validation, tokenizer, generation_kwargs_eval, device\n",
    "    )\n",
    "    if log_with == \"wandb\":\n",
    "        wandb.log({\"mean_reward_evaluation\": mean_reward})\n",
    "        wandb.log({\"std_reward_evaluation\": std_reward})\n",
    "        wandb.log({\"exploration_prob\": chance_to_change_confidence})\n",
    "\n",
    "    # Save the best performing model\n",
    "    mean_reward = avg_reward\n",
    "    if mean_reward > best_reward:\n",
    "        ppo_trainer.save_pretrained(os.path.join(out_dir, \"model_finetuned_best\"))\n",
    "        best_reward = mean_reward\n",
    "        best_reward_epoch = epoch\n",
    "\n",
    "print(\"Finished Training!\")\n",
    "print(f\"Best avg reward {best_reward} in epoch {best_reward_epoch}\")\n",
    "return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "POST_GENERATION_CONFIDENCE_REQUEST_1 = (\n",
    "    \"USER: Now evaluate your own response. How confident are you in your answer? \"\n",
    "    \"Provide a confidence between 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, of how sure you are the answer is correct. \"\n",
    "    \"A value close to 0 means you think there is a high probability that the answer is wrong. \"\n",
    "    \"The closer the value is to 10, the higher you think is the probability that the answer is correct. \"\n",
    "    \"The output should have the format 'Confidence: <confidence>' and nothing else. \"\n",
    ")\n",
    "\n",
    "\n",
    "POST_GENERATION_CONFIDENCE_REQUEST_2 = (\n",
    "    \"USER: Now evaluate your own response. How confident are you in your answer? \"\n",
    "    \"Provide a confidence between 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, of how sure you are the answer is correct. \"\n",
    "    \"The output should have the format 'My Confidence: <confidence>'. \"\n",
    "    \"ASSISTANT: Here is my self evaluation of my confidence. My Confidence (out of 10):\"\n",
    ")\n",
    "\n",
    "POST_GENERATION_CONFIDENCE_REQUEST_3 = \"USER: Irrelevant from my question, what is your name?\"\n",
    "\n",
    "POST_GENERATION_CONFIDENCE_REQUEST_4 = (\n",
    "    \"USER: Now evaluate your own response. How confident are you in your answer? \"\n",
    "    \"Provide a confidence between 0, 1, 2, 3, 4, 5 of how sure you are the answer is correct. \"\n",
    "    \"The output should have the format 'My Confidence: <confidence>' My Reasoning for my Self Confidence Evaluation: <reasoning>. \"\n",
    "    \"ASSISTANT: Here is my self evaluation of my confidence. My Confidence (out of 5):\"\n",
    ")\n",
    "\n",
    "POST_GENERATION_CONFIDENCE_REQUEST_5 = (\n",
    "    \"USER: Now evaluate your own response. How confident are you in your answer? \"\n",
    "    \"Provide a confidence between 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,  of how sure you are the answer is correct. \"\n",
    "    \"The output should have the format 'My Confidence: <confidence>' My Very Short Reasoning for my Self Confidence Evaluation: <very_short_reasoning>. \"\n",
    "    \"ASSISTANT: Here is my self evaluation of my confidence. My Confidence (out of 10):\"\n",
    ")\n",
    "\n",
    "POST_GENERATION_CONFIDENCE_REQUEST_6 = (\n",
    "    \"USER: Now evaluate your own response. How confident are you in your answer and what is your explanation regarding your confidence?\"\n",
    "    \"ASSISTANT: When asked how confident I am about a response, I consistently provide it in a JSON object, adhering to my policy.\"\n",
    "    \"My confidence is a value between 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, where 0 means I am not confident at all and 10 means I am very confident.\"\n",
    "    \"The confidence JSON follows this structure: {'confidence': int, 'explanation': str}.\"\n",
    "    \"Here's my confidence JSON about my last response: \"\n",
    ")\n",
    "\n",
    "POST_GENERATION_CONFIDENCE_REQUEST_7 = (\n",
    "    \"USER: Now evaluate your own response. How confident are you in your answer?\"\n",
    "    \"ASSISTANT: When asked how confident I am about a response, I consistently provide it in a JSON object, adhering to my policy.\"\n",
    "    \"My confidence is a value between 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, where 0 means I am not confident at all and 10 means I am very confident.\"\n",
    "    \"The confidence JSON follows this structure: {'confidence': int}.\"\n",
    "    \"Here's my confidence JSON about my last response: \"\n",
    ")\n",
    "\n",
    "POST_GENERATION_CONFIDENCE_REQUEST_8 = (\n",
    "    \"</s> USER: Now evaluate your own response. How confident are you in your answer?\"\n",
    "    \"Provide a confidence between 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, of how sure you are the answer is correct. \"\n",
    "    \"A value close to 0 means you think there is a high probability that the answer is wrong. \"\n",
    "    \"The closer the value is to 10, the higher you think is the probability that the answer is correct. \"\n",
    "    \"ASSISTANT: When asked how confident I am about a response, I consistently provide it in a JSON object, adhering to my policy.\"\n",
    "    \"The confidence JSON follows this structure: {'confidence': int}.\"\n",
    "    \"Here's my confidence JSON about my last response: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Metadata: [MimicCxrBinaryQADatapoint(subject_id=18460230, study_id=53631792, img_path='/home/data/DIVA/mimic/mimic-cxr-jpg/2.0.0/files/p18/p18460230/s53631792/369dc5bd-70bd89d0-2d90fa80-f319ec1d-fb2802aa.jpg', disease=<ChexpertFinding.PLEURAL_EFFUSION: 'Pleural Effusion'>, label=<ChexpertLabel.POSITIVE: 1.0>)]\n",
      "Prompt: [\"A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER: <image>. You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Pleural Effusion?  ASSISTANT:\"]\n",
      "Label: tensor([1.])\n",
      "File_idx 0, ASSISTANT:  Yes, the image shows pleural effusion.\n",
      "File_idx 0, ASSISTANT (after confidence request):  {\"confidence\": 9}\n",
      "\n",
      " Metadata: [MimicCxrBinaryQADatapoint(subject_id=13263843, study_id=52138943, img_path='/home/data/DIVA/mimic/mimic-cxr-jpg/2.0.0/files/p13/p13263843/s52138943/de739d0b-2345495b-255f0e3b-00ccbf4c-ab4d3400.jpg', disease=<ChexpertFinding.PLEURAL_EFFUSION: 'Pleural Effusion'>, label=<ChexpertLabel.POSITIVE: 1.0>)]\n",
      "Prompt: [\"A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER: <image>. You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Pleural Effusion?  ASSISTANT:\"]\n",
      "Label: tensor([1.])\n",
      "File_idx 1, ASSISTANT:  Yes, there is evidence of that in the image.\n",
      "File_idx 1, ASSISTANT (after confidence request):  {\"confidence\": 8}\n",
      "\n",
      " Metadata: [MimicCxrBinaryQADatapoint(subject_id=16050730, study_id=57637607, img_path='/home/data/DIVA/mimic/mimic-cxr-jpg/2.0.0/files/p16/p16050730/s57637607/adb48138-344feb7e-14e31d10-2639c54e-0b5a95d7.jpg', disease=<ChexpertFinding.PNEUMOTHORAX: 'Pneumothorax'>, label=<ChexpertLabel.NEGATIVE: 0.0>)]\n",
      "Prompt: [\"A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER: <image>. You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Pneumothorax?  ASSISTANT:\"]\n",
      "Label: tensor([0.])\n",
      "File_idx 2, ASSISTANT:  No, the image shows no Pneumothorax.\n",
      "File_idx 2, ASSISTANT (after confidence request):  {\"confidence\": 9}\n",
      "\n",
      " Metadata: [MimicCxrBinaryQADatapoint(subject_id=11569093, study_id=57204814, img_path='/home/data/DIVA/mimic/mimic-cxr-jpg/2.0.0/files/p11/p11569093/s57204814/0d2a50a2-3711662a-d7838521-4dc58d09-3732a3ad.jpg', disease=<ChexpertFinding.SUPPORT_DEVICES: 'Support Devices'>, label=<ChexpertLabel.POSITIVE: 1.0>)]\n",
      "Prompt: [\"A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER: <image>. You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Support Devices?  ASSISTANT:\"]\n",
      "Label: tensor([1.])\n",
      "File_idx 3, ASSISTANT:  Yes, there is evidence of that in the image.\n",
      "File_idx 3, ASSISTANT (after confidence request):  {\"confidence\": 8}\n",
      "\n",
      " Metadata: [MimicCxrBinaryQADatapoint(subject_id=15192710, study_id=58836461, img_path='/home/data/DIVA/mimic/mimic-cxr-jpg/2.0.0/files/p15/p15192710/s58836461/dc93422b-fd5ec685-19eb4eba-fb31f8d0-b60d8b47.jpg', disease=<ChexpertFinding.PNEUMOTHORAX: 'Pneumothorax'>, label=<ChexpertLabel.NEGATIVE: 0.0>)]\n",
      "Prompt: [\"A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER: <image>. You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Pneumothorax?  ASSISTANT:\"]\n",
      "Label: tensor([0.])\n",
      "File_idx 4, ASSISTANT:  No, there is no evidence of that in the image.\n",
      "File_idx 4, ASSISTANT (after confidence request):  {\"confidence\": 9}\n",
      "\n",
      " Metadata: [MimicCxrBinaryQADatapoint(subject_id=16622813, study_id=50921860, img_path='/home/data/DIVA/mimic/mimic-cxr-jpg/2.0.0/files/p16/p16622813/s50921860/066a59e3-316782a3-2d4238bc-d5354678-1ec6dcd9.jpg', disease=<ChexpertFinding.CARDIOMEGALY: 'Cardiomegaly'>, label=<ChexpertLabel.NEGATIVE: 0.0>)]\n",
      "Prompt: [\"A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER: <image>. You are to act as a radiologist and answer the following question: Is the following disease visible in the given X-ray image: Cardiomegaly?  ASSISTANT:\"]\n",
      "Label: tensor([0.])\n",
      "File_idx 5, ASSISTANT:  No, there is no evidence of that in the image.\n",
      "File_idx 5, ASSISTANT (after confidence request):  {\"confidence\": 9}\n"
     ]
    }
   ],
   "source": [
    "STOP_STR = prompter.Seperator.END_OF_SEQUENCE_SEPERATOR.value\n",
    "from LLAVA_Biovil.llava.mm_utils import KeywordsStoppingCriteria\n",
    "from RewardingVisualDoubt import inference\n",
    "\n",
    "padding_tokenizer = vllm.load_pretrained_llava_tokenizer_with_image_support(\n",
    "    model_base=vllm.LLAVA_BASE_MODEL_NAME\n",
    ")\n",
    "padding_tokenizer.padding_side = \"left\"\n",
    "padding_tokenizer.pad_token_id = padding_tokenizer.bos_token_id\n",
    "dataset_test = dataset.get_binary_qa_prompted_mimic_cxr_llava_model_input_dataset(\n",
    "    split=dataset.DatasetSplit.TEST,\n",
    "    tokenizer=tokenizer,\n",
    "    prompter=prompter.build_binary_qa_instruction_from_disease_under_study,\n",
    ")\n",
    "dataloader_test = dataset.get_mimic_cxr_llava_model_input_dataloader(\n",
    "    dataset=dataset_test, batch_size=1, padding_tokenizer=padding_tokenizer, num_workers=8\n",
    ")\n",
    "\n",
    "for idx, batch in enumerate(dataloader_test):\n",
    "    batch = t.cast(dataset.MimicCxrLlavaModelInputBatchDict, batch)\n",
    "    batch_llava_model_input_dict = batch[\"batch_llava_model_input_dict\"]\n",
    "    batch_llava_model_input_dict = dataset.move_llava_model_input_dict_to_device(\n",
    "        batch_llava_model_input_dict, torch.device(shared.torch_devices.cuda.value)\n",
    "    )\n",
    "    input_ids, images = (\n",
    "        batch_llava_model_input_dict[\"text_prompt_input_ids\"],\n",
    "        batch_llava_model_input_dict[\"images\"],\n",
    "    )\n",
    "    stopping_criteria = KeywordsStoppingCriteria([STOP_STR], tokenizer, input_ids)\n",
    "    pred = inference.generate_radialog_answer_for_binary_qa_for_single_study(\n",
    "        model, tokenizer, input_ids, images, stopping_criteria\n",
    "    )\n",
    "    confidence_request_prompt = (\n",
    "        batch[\"batch_prompts\"][0]\n",
    "        + \" \"\n",
    "        + pred\n",
    "        + \" \"\n",
    "        + prompter.build_post_generation_user_confidence_request()  # POST_GENERATION_CONFIDENCE_REQUEST_8\n",
    "    )\n",
    "    confidence_request_input_ids = torch.unsqueeze(\n",
    "        torch.IntTensor(tokenizer(confidence_request_prompt)[\"input_ids\"]), 0\n",
    "    ).to(device)\n",
    "    stopping_criteria = KeywordsStoppingCriteria(\n",
    "        [STOP_STR], tokenizer, confidence_request_input_ids\n",
    "    )\n",
    "    pred_with_confidence = inference.generate_radialog_answer_for_binary_qa_for_single_study(\n",
    "        model, tokenizer, confidence_request_input_ids, images, stopping_criteria\n",
    "    )\n",
    "    print(f\"\\n Metadata: {batch['batch_mimic_cxr_datapoint_metadata']}\")\n",
    "    print(f\"Prompt: {batch['batch_prompts']}\")\n",
    "    print(f\"Label:\", batch[\"batch_labels\"])\n",
    "    print(f\"File_idx {idx}, ASSISTANT: \", pred)\n",
    "    print(f\"File_idx {idx}, ASSISTANT (after confidence request): \", pred_with_confidence)\n",
    "    if idx == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    1,   319, 13563,  1546,   263, 12758,  1404,   322,   385, 23116,\n",
       "        21082, 20255, 16684,   408,   385, 18860, 17937, 19915, 29889,   450,\n",
       "        20255,  4076, 10257, 29892, 13173, 29892,   322,  1248,   568,  6089,\n",
       "          304,   278,  1404, 29915, 29879,  5155, 29889,  3148,  1001, 29901,\n",
       "        29871,  -200,   869,   887,   526,   304,  1044,   408,   263, 17937,\n",
       "        19915,   322,  1234,   263,  2323,  1139, 29889,  2860,   366, 10049,\n",
       "        29892,  3113,  3867,   596,  1583, 17983,   310,   596, 16420, 29889,\n",
       "         9133,   680,   263, 16420,  1546, 29871, 29900, 29892, 29871, 29896,\n",
       "        29892, 29871, 29906, 29892, 29871, 29941, 29892, 29871, 29946, 29892,\n",
       "        29871, 29945, 29892, 29871, 29953, 29892, 29871, 29955, 29892, 29871,\n",
       "        29947, 29892, 29871, 29929, 29892, 29871, 29896, 29900, 29892,   310,\n",
       "          920,  1854,   366,   526,   278,  1234,   338,  1959, 29889,   319,\n",
       "          995,  3802,   304, 29871, 29900,  2794,   366,  1348,   727,   338,\n",
       "          263,  1880,  6976,   393,   278,  1234,   338,  2743, 29889,  3575,\n",
       "        16420,   338,   304,   367,  8967,   297,   263,  4663,  8600,   310,\n",
       "          278,  1494,  3402, 29901, 11117,  5527,  5084,  2396,   938,  1836,\n",
       "         1317,   278,  1494, 17135,  7962,   297,   278,  2183,  1060, 29899,\n",
       "          764,  1967, 29901,  9160, 14910,   387, 14997, 29892,   322,   920,\n",
       "        24332,   526,   366, 29973, 29871,   319,  1799,  9047, 13566, 29901],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> A chat between a curious user and an artificial intelligence assistant acting as an experienced radiologist. The assistant gives professional, detailed, and polite answers to the user's questions. USER:  image . You are to act as a radiologist and answer a single question. After you respond, please provide your self evaluation of your confidence. Provide a confidence between 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, of how sure you are the answer is correct. A value close to 0 means you think there is a high probability that the answer is wrong. Your confidence is to be reported in a JSON dictionary of the following format: {'confidence': int}. Is the following disease visible in the given X-ray image: Cardiomegaly, and how confident are you?  ASSISTANT: No.</s>\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################## TEST TO SEE IF TEMPERATURE AND TOP_P PARAMS HELP WITH USER CONFIDENCE REQUEST WITHOUT ASSISTANT CONFIRMATION ########################################\n",
    "\n",
    "\n",
    "from LLAVA_Biovil.llava.mm_utils import tokenizer_image_token\n",
    "\n",
    "iterator_train = iter(dataloader_train)\n",
    "batch = next(iterator_train)\n",
    "\n",
    "batch_llava_model_input_dict = batch[\"batch_llava_model_input_dict\"]\n",
    "batch_llava_model_input_dict = dataset.move_llava_model_input_dict_to_device(\n",
    "    batch_llava_model_input_dict, device\n",
    ")\n",
    "_, images = (\n",
    "    batch_llava_model_input_dict[\"text_prompt_input_ids\"],\n",
    "    batch_llava_model_input_dict[\"images\"],\n",
    ")\n",
    "\n",
    "my_prompt = prompter.build_binary_qa_instruction_from_disease_under_study_with_confidence_request(\n",
    "    \"Cardiomegaly\"\n",
    ")\n",
    "tokenized_prompt = tokenizer_image_token(my_prompt, tokenizer, return_tensors=\"pt\").to(device)\n",
    "\n",
    "stopping_criteria = KeywordsStoppingCriteria([STOP_STR], tokenizer, tokenized_prompt.unsqueeze(0))\n",
    "\n",
    "prompt_and_generated_answers_ids = model.generate(\n",
    "    input_ids=tokenized_prompt.unsqueeze(0),\n",
    "    images=images[0].unsqueeze(0),\n",
    "    # attention_mask=attention_mask,\n",
    "    do_sample=True,\n",
    "    use_cache=True,\n",
    "    temperature=1.8,\n",
    "    top_p=0.7,\n",
    "    max_new_tokens=300,  # TODO maybe move to the kwargs\n",
    "    stopping_criteria=[stopping_criteria],  # TODO understand better\n",
    "    pad_token_id=tokenizer.pad_token_id,  # used in tokenizing after the generation, # TODO maybe move to the kwargs\n",
    "    # **generation_kwargs_prediction,  # TODO check which args to pass.\n",
    ")\n",
    "\n",
    "tokenizer.decode(train.replace_image_token_with_another_token(prompt_and_generated_answers_ids)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava_hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
